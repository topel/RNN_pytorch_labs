{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Lab-01:-Vanilla-RNN---demo\" data-toc-modified-id=\"Lab-01:-Vanilla-RNN---demo-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Lab 01: Vanilla RNN - demo</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#With-or-without-GPU?\" data-toc-modified-id=\"With-or-without-GPU?-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>With or without GPU?</a></span></li><li><span><a href=\"#Download-Penn-Tree-Bank\" data-toc-modified-id=\"Download-Penn-Tree-Bank-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Download Penn Tree Bank</a></span></li><li><span><a href=\"#Some-constants-associated-with-the-data-set\" data-toc-modified-id=\"Some-constants-associated-with-the-data-set-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Some constants associated with the data set</a></span></li><li><span><a href=\"#Make-a-recurrent-net-class\" data-toc-modified-id=\"Make-a-recurrent-net-class-1.0.4\"><span class=\"toc-item-num\">1.0.4&nbsp;&nbsp;</span>Make a recurrent net class</a></span></li><li><span><a href=\"#Build-the-net.-Choose-the-hidden-size-to-be-150.-How-many-parameters-in-total?\" data-toc-modified-id=\"Build-the-net.-Choose-the-hidden-size-to-be-150.-How-many-parameters-in-total?-1.0.5\"><span class=\"toc-item-num\">1.0.5&nbsp;&nbsp;</span>Build the net. Choose the hidden size to be 150. How many parameters in total?</a></span></li><li><span><a href=\"#Send-the-weights-of-the-networks-to-the-GPU\" data-toc-modified-id=\"Send-the-weights-of-the-networks-to-the-GPU-1.0.6\"><span class=\"toc-item-num\">1.0.6&nbsp;&nbsp;</span>Send the weights of the networks to the GPU</a></span></li><li><span><a href=\"#Set-up-manually-the-weights-of-the-embedding-module-and-Linear-module\" data-toc-modified-id=\"Set-up-manually-the-weights-of-the-embedding-module-and-Linear-module-1.0.7\"><span class=\"toc-item-num\">1.0.7&nbsp;&nbsp;</span>Set up manually the weights of the embedding module and Linear module</a></span></li><li><span><a href=\"#Choose-the-criterion,-as-well-as-the-following-important-hyperparameters:\" data-toc-modified-id=\"Choose-the-criterion,-as-well-as-the-following-important-hyperparameters:-1.0.8\"><span class=\"toc-item-num\">1.0.8&nbsp;&nbsp;</span>Choose the criterion, as well as the following important hyperparameters:</a></span></li><li><span><a href=\"#Function-to-evaluate-the-network-on-the-test-set\" data-toc-modified-id=\"Function-to-evaluate-the-network-on-the-test-set-1.0.9\"><span class=\"toc-item-num\">1.0.9&nbsp;&nbsp;</span>Function to evaluate the network on the test set</a></span></li><li><span><a href=\"#Do-10-passes-through-the-training-set-(100-passes-would-reach-135-on-test-set)\" data-toc-modified-id=\"Do-10-passes-through-the-training-set-(100-passes-would-reach-135-on-test-set)-1.0.10\"><span class=\"toc-item-num\">1.0.10&nbsp;&nbsp;</span>Do 10 passes through the training set (100 passes would reach 135 on test set)</a></span></li><li><span><a href=\"#Choose-one-sentence-(taken-from-the-test-set)\" data-toc-modified-id=\"Choose-one-sentence-(taken-from-the-test-set)-1.0.11\"><span class=\"toc-item-num\">1.0.11&nbsp;&nbsp;</span>Choose one sentence (taken from the test set)</a></span></li><li><span><a href=\"#Convert-the-sentence-into-a-vector,-then-send-to-GPU\" data-toc-modified-id=\"Convert-the-sentence-into-a-vector,-then-send-to-GPU-1.0.12\"><span class=\"toc-item-num\">1.0.12&nbsp;&nbsp;</span>Convert the sentence into a vector, then send to GPU</a></span></li><li><span><a href=\"#Set-the-initial-hidden-state-to-zero,-then-run-the-RNN.\" data-toc-modified-id=\"Set-the-initial-hidden-state-to-zero,-then-run-the-RNN.-1.0.13\"><span class=\"toc-item-num\">1.0.13&nbsp;&nbsp;</span>Set the initial hidden state to zero, then run the RNN.</a></span></li><li><span><a href=\"#Display-the-network-prediction-for-the-next-word\" data-toc-modified-id=\"Display-the-network-prediction-for-the-next-word-1.0.14\"><span class=\"toc-item-num\">1.0.14&nbsp;&nbsp;</span>Display the network prediction for the next word</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01: Vanilla RNN - demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:04:43.782274Z",
     "start_time": "2019-11-20T12:04:43.770070Z"
    }
   },
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    file_name = 'vrnn_demo.ipynb'\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:40:50.719830Z",
     "start_time": "2019-11-20T16:40:50.122421Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With or without GPU?\n",
    "\n",
    "It is recommended to run this code on GPU:<br> \n",
    "* Time for 1 epoch on CPU : 153 sec ( 2.55 min)<br> \n",
    "* Time for 1 epoch on GPU : 8.4 sec w/ GeForce GTX 1080 Ti <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:40:50.727643Z",
     "start_time": "2019-11-20T16:40:50.723749Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:40:50.750845Z",
     "start_time": "2019-11-20T16:40:50.730068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda GeForce GTX TITAN X\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device, torch.cuda.get_device_name(device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:40:50.787370Z",
     "start_time": "2019-11-20T16:40:50.784293Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Penn Tree Bank\n",
    "\n",
    "The tensor train_data consists of 20 columns of 46,479 words.<br>\n",
    "The tensor test_data consists of 20 columns of 4,121 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:40:54.429741Z",
     "start_time": "2019-11-20T16:40:54.412972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20542, 20])\n",
      "torch.Size([74, 20])\n"
     ]
    }
   ],
   "source": [
    "from utils import check_ptb_dataset_exists\n",
    "data_path=check_ptb_dataset_exists()\n",
    "\n",
    "train_data  =  torch.load(data_path+'librivox_fr/train_data.pt')\n",
    "test_data   =  torch.load(data_path+'librivox_fr/test_data.pt')\n",
    "\n",
    "print(  train_data.size()  )\n",
    "print(  test_data.size()   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:05.971233Z",
     "start_time": "2019-11-20T16:41:05.962847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 20])\n",
      "tensor([[   1,   28,  170,  640,  446,  210,  138, 1734,  365,   20,   20, 2885,\n",
      "         2678,  193,  773,   25,  377,  328, 3061, 4869],\n",
      "        [   2,  457,   43,   13,  122,  256,    5, 4486,   36,   23,   34,    0,\n",
      "          124, 1956,  235, 4466,    0, 7351,  369,    0]])\n"
     ]
    }
   ],
   "source": [
    "seq_length = 35\n",
    "for count in range( 0 , 20542-seq_length ,  seq_length):\n",
    "\n",
    "    # create a minibatch\n",
    "    minibatch_data =  train_data[ count   : count+seq_length   ]\n",
    "    print(minibatch_data.shape)\n",
    "    print(minibatch_data[:2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:07.163657Z",
     "start_time": "2019-11-20T16:41:07.049160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9573), 9574)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(torch.unique(train_data)), len((torch.unique(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:07.437114Z",
     "start_time": "2019-11-20T16:41:07.424767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9575), 503)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(torch.unique(test_data)), len((torch.unique(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:32:12.463892Z",
     "start_time": "2019-11-20T16:32:12.458417Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some constants associated with the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:09.685646Z",
     "start_time": "2019-11-20T16:41:09.681963Z"
    }
   },
   "outputs": [],
   "source": [
    "bs = 20 # if you change this, also change this in generate_librivox_fr\n",
    "# bs = 10\n",
    "\n",
    "# vocab_size = 17498 # if WORD_OCC_THRESHOLD == 1\n",
    "vocab_size = 9574 # if WORD_OCC_THRESHOLD == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a recurrent net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:10.266373Z",
     "start_time": "2019-11-20T16:41:10.257454Z"
    }
   },
   "outputs": [],
   "source": [
    "class three_layer_recurrent_net(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(three_layer_recurrent_net, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Embedding( vocab_size  , hidden_size  )\n",
    "        self.layer2 = nn.RNN(       hidden_size , hidden_size  )\n",
    "        self.layer3 = nn.Linear(    hidden_size , vocab_size   )\n",
    "\n",
    "        \n",
    "    def forward(self, word_seq, h_init ):\n",
    "        \n",
    "        g_seq               =   self.layer1( word_seq )  \n",
    "        h_seq , h_final     =   self.layer2( g_seq , h_init )\n",
    "        score_seq           =   self.layer3( h_seq )\n",
    "        \n",
    "        return score_seq,  h_final \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the net. Choose the hidden size to be 150. How many parameters in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:10.707393Z",
     "start_time": "2019-11-20T16:41:10.624850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three_layer_recurrent_net(\n",
      "  (layer1): Embedding(9574, 50)\n",
      "  (layer2): RNN(50, 50)\n",
      "  (layer3): Linear(in_features=50, out_features=9574, bias=True)\n",
      ")\n",
      "There are 972074 (0.97 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "hidden_size=50\n",
    "\n",
    "net = three_layer_recurrent_net( hidden_size )\n",
    "\n",
    "print(net)\n",
    "\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send the weights of the networks to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:13.654684Z",
     "start_time": "2019-11-20T16:41:10.984749Z"
    }
   },
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up manually the weights of the embedding module and Linear module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:13.660837Z",
     "start_time": "2019-11-20T16:41:13.656998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.layer1.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "net.layer3.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the criterion, as well as the following important hyperparameters: \n",
    "* initial learning rate = 1\n",
    "* sequence length = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:13.732479Z",
     "start_time": "2019-11-20T16:41:13.662089Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "my_lr = 1\n",
    "\n",
    "seq_length = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evaluate the network on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:32:23.343122Z",
     "start_time": "2019-11-20T16:32:23.331363Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "       \n",
    "    h = torch.zeros(1, bs, hidden_size)\n",
    "    \n",
    "    h=h.to(device)\n",
    "\n",
    "       \n",
    "    for count in range( 0 , 74-seq_length ,  seq_length) :\n",
    "               \n",
    "        minibatch_data =  test_data[ count   : count+seq_length   ]\n",
    "        minibatch_label = test_data[ count+1 : count+seq_length+1 ]\n",
    "        \n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "                                  \n",
    "        scores, h  = net( minibatch_data, h )\n",
    "        \n",
    "        minibatch_label =   minibatch_label.view(  bs*seq_length ) \n",
    "        scores          =            scores.view(  bs*seq_length , vocab_size)\n",
    "        \n",
    "        loss = criterion(  scores ,  minibatch_label )    \n",
    "        \n",
    "        h=h.detach()\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1        \n",
    "    \n",
    "    total_loss = running_loss/num_batches \n",
    "    print('test: exp(loss) = ', math.exp(total_loss)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do 10 passes through the training set (100 passes would reach 135 on test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:41:43.732680Z",
     "start_time": "2019-11-20T16:41:17.828346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch= 0 \t time= 2.5484092235565186 \t lr= 1 \t exp(loss)= 683.3492200973142\n",
      "\n",
      "epoch= 1 \t time= 5.117347717285156 \t lr= 1 \t exp(loss)= 413.63328776051367\n",
      "\n",
      "epoch= 2 \t time= 7.706781625747681 \t lr= 1 \t exp(loss)= 318.7099496793693\n",
      "\n",
      "epoch= 3 \t time= 10.250564098358154 \t lr= 1 \t exp(loss)= 265.82340066046135\n",
      "\n",
      "epoch= 4 \t time= 12.89343786239624 \t lr= 0.9090909090909091 \t exp(loss)= 232.74181976756424\n",
      "\n",
      "epoch= 5 \t time= 15.543511867523193 \t lr= 0.8264462809917354 \t exp(loss)= 211.59802737378558\n",
      "\n",
      "epoch= 6 \t time= 18.28880524635315 \t lr= 0.7513148009015777 \t exp(loss)= 196.66495896463357\n",
      "\n",
      "epoch= 7 \t time= 20.686213731765747 \t lr= 0.6830134553650705 \t exp(loss)= 185.55740052879185\n",
      "\n",
      "epoch= 8 \t time= 23.173760652542114 \t lr= 0.6209213230591549 \t exp(loss)= 176.86018173652417\n",
      "\n",
      "epoch= 9 \t time= 25.88524031639099 \t lr= 0.5644739300537771 \t exp(loss)= 169.8470620771973\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    # keep the learning rate to 1 during the first 4 epochs, then divide by 1.1 at every epoch\n",
    "    if epoch >= 4:\n",
    "        my_lr = my_lr / 1.1\n",
    "    \n",
    "    # create a new optimizer and give the current learning rate.   \n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n",
    "        \n",
    "    # set the running quantities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "       \n",
    "    # set the initial h to be the zero vector\n",
    "    h = torch.zeros(1, bs, hidden_size)\n",
    "\n",
    "    # send it to the gpu    \n",
    "    h=h.to(device)\n",
    "    \n",
    "    for count in range( 0 , 20542-seq_length ,  seq_length):\n",
    "             \n",
    "        # Set the gradients to zeros\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # create a minibatch\n",
    "        minibatch_data =  train_data[ count   : count+seq_length   ]\n",
    "        minibatch_label = train_data[ count+1 : count+seq_length+1 ]        \n",
    "        \n",
    "        # send them to the gpu\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        # Detach to prevent from backpropagating all the way to the beginning\n",
    "        # Then tell Pytorch to start tracking all operations that will be done on h and c\n",
    "        h=h.detach()\n",
    "        h=h.requires_grad_()\n",
    "                       \n",
    "        # forward the minibatch through the net        \n",
    "        scores, h  = net( minibatch_data, h )\n",
    "        \n",
    "        # reshape the scores and labels to huge batch of size bs*seq_length\n",
    "        scores          =            scores.view(  bs*seq_length , vocab_size)  \n",
    "        minibatch_label =   minibatch_label.view(  bs*seq_length )       \n",
    "        \n",
    "        # Compute the average of the losses of the data points in this huge batch\n",
    "        loss = criterion(  scores ,  minibatch_label )\n",
    "        \n",
    "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step of stochastic gradient descent: R=R-lr(dL/dR), V=V-lr(dL/dV), ...\n",
    "        utils.normalize_gradient(net)\n",
    "        optimizer.step()\n",
    "        \n",
    "            \n",
    "        # update the running loss  \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    # compute stats for the full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    elapsed = time.time()-start\n",
    "    \n",
    "    print('')\n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'\\t lr=', my_lr, '\\t exp(loss)=',  math.exp(total_loss))\n",
    "#     eval_on_test_set() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Choose one sentence (taken from the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T17:05:27.162082Z",
     "start_time": "2019-11-20T17:05:27.156992Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence1 = \"on entendait vaguement au dehors les\"\n",
    "\n",
    "sentence2 = \"hier je luttai de la sorte contre le grand\"\n",
    "\n",
    "sentence3 = \"il connaissait la route et nous avons\"\n",
    "\n",
    "sentence4 = \"i think my line has been very consistent mrs. hills said at a news\"\n",
    "\n",
    "sentence5 = \"this appears particularly true at gm which had strong sales in\"\n",
    "\n",
    "# or make your own sentence.  No capital letter or punctuation allowed. Each word must be in the allowed vocabulary.\n",
    "sentence6= \"he was very\"\n",
    "\n",
    "# SELECT THE SENTENCE HERE\n",
    "mysentence = sentence1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the sentence into a vector, then send to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T17:04:02.934354Z",
     "start_time": "2019-11-20T17:04:02.928125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 370],\n",
      "        [3291],\n",
      "        [  23],\n",
      "        [ 636],\n",
      "        [   8],\n",
      "        [ 457],\n",
      "        [ 695]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "minibatch_data=utils.sentence2vector_librivox_fr(mysentence)\n",
    "      \n",
    "minibatch_data=minibatch_data.to(device)\n",
    "\n",
    "print(minibatch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the initial hidden state to zero, then run the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:53:08.598182Z",
     "start_time": "2019-11-20T16:53:08.587019Z"
    }
   },
   "outputs": [],
   "source": [
    "h = torch.zeros(1, 1, hidden_size)\n",
    "h=h.to(device)\n",
    "\n",
    "scores , h = net( minibatch_data , h )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the network prediction for the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:44:42.888593Z",
     "start_time": "2019-11-20T16:44:42.869284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il connaissait la route et nous avons ... \n",
      "\n",
      "6.6%\t <unk>\n",
      "4.1%\t fait\n",
      "3.5%\t de\n",
      "3.4%\t été\n",
      "2.8%\t à\n",
      "2.3%\t eu\n",
      "2.1%\t dit\n",
      "1.9%\t en\n",
      "1.8%\t vu\n",
      "1.7%\t plus\n",
      "1.5%\t bien\n",
      "1.5%\t des\n",
      "1.4%\t un\n",
      "1.1%\t la\n",
      "1.0%\t les\n",
      "1.0%\t encore\n",
      "0.9%\t donné\n",
      "0.9%\t une\n",
      "0.8%\t toujours\n",
      "0.8%\t pris\n",
      "0.8%\t pour\n",
      "0.8%\t que\n",
      "0.7%\t le\n",
      "0.7%\t dans\n",
      "0.7%\t pu\n",
      "0.7%\t mis\n",
      "0.6%\t donc\n",
      "0.6%\t raison\n",
      "0.6%\t déjà\n",
      "0.6%\t <eos>\n"
     ]
    }
   ],
   "source": [
    "print(mysentence, '... \\n')\n",
    "\n",
    "utils.show_next_word(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:58:17.783099Z",
     "start_time": "2019-11-20T16:58:17.766347Z"
    }
   },
   "outputs": [],
   "source": [
    "path_data = '../'\n",
    "word2idx  =  torch.load(path_data + 'librivox_fr/word2idx.pt')\n",
    "idx2word  =  torch.load(path_data + 'librivox_fr/idx2word.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T17:01:14.255199Z",
     "start_time": "2019-11-20T17:01:14.247985Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_word(scores):\n",
    "    prob=F.softmax(scores,dim=2)\n",
    "    num_word_display = 2\n",
    "    p=prob[-1].squeeze()\n",
    "    p, word_idx = torch.topk(p, num_word_display)\n",
    "#     print(p, word_idx)\n",
    "    if word_idx[0] == 0:\n",
    "        return idx2word[word_idx[1]]\n",
    "    else:\n",
    "        return idx2word[word_idx[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T16:58:18.724332Z",
     "start_time": "2019-11-20T16:58:18.708636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0664, 0.0412], device='cuda:0', grad_fn=<TopkBackward>) tensor([  0, 503], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fait'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word = get_next_word(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T17:05:30.097574Z",
     "start_time": "2019-11-20T17:05:30.068814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on entendait vaguement au dehors les...\n",
      "on entendait vaguement au dehors les autres...\n",
      "on entendait vaguement au dehors les autres et...\n",
      "on entendait vaguement au dehors les autres et les...\n",
      "on entendait vaguement au dehors les autres et les autres...\n",
      "on entendait vaguement au dehors les autres et les autres et...\n",
      "on entendait vaguement au dehors les autres et les autres et les...\n",
      "on entendait vaguement au dehors les autres et les autres et les autres...\n",
      "on entendait vaguement au dehors les autres et les autres et les autres et...\n",
      "on entendait vaguement au dehors les autres et les autres et les autres et les...\n",
      "on entendait vaguement au dehors les autres et les autres et les autres et les autres...\n"
     ]
    }
   ],
   "source": [
    "print(mysentence + '...')\n",
    "\n",
    "i= 0\n",
    "not_finished = True\n",
    "while i < 10 and not_finished :\n",
    "\n",
    "    minibatch_data=utils.sentence2vector_librivox_fr(mysentence)\n",
    "      \n",
    "    minibatch_data=minibatch_data.to(device)\n",
    "    h = torch.zeros(1, 1, hidden_size)\n",
    "    h=h.to(device)\n",
    "    scores , h = net( minibatch_data , h )\n",
    "    \n",
    "    next_word = get_next_word(scores)\n",
    "    mysentence += ' ' + next_word\n",
    "    print(mysentence + '...')\n",
    "    not_finished = next_word != '<eos>'\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
