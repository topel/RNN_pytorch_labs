{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "TP2_classification_de_noms_STUDENT.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/topel/RNN_pytorch_labs/blob/master/TP2_classification_de_noms_STUDENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "eV8IcwuD2uEV",
        "colab_type": "text"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#RNN-à-partir-de-caractères\" data-toc-modified-id=\"RNN-à-partir-de-caractères-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>RNN à partir de caractères</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Préparation-des-données\" data-toc-modified-id=\"Préparation-des-données-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Préparation des données</a></span></li><li><span><a href=\"#Création-du-RNN\" data-toc-modified-id=\"Création-du-RNN-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Création du RNN</a></span></li><li><span><a href=\"#Création-de-votre-propre-modèle-RNN\" data-toc-modified-id=\"Création-de-votre-propre-modèle-RNN-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Création de votre propre modèle RNN</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Évaluation\" data-toc-modified-id=\"Évaluation-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Évaluation</a></span></li><li><span><a href=\"#Visualizing-memorization\" data-toc-modified-id=\"Visualizing-memorization-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Visualizing memorization</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8xKuiUA2uEZ",
        "colab_type": "text"
      },
      "source": [
        "# RNN à partir de caractères"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPo8EN-Q2uEa",
        "colab_type": "text"
      },
      "source": [
        "Dans ce TP, l'objectif est de construire un RNN simple qui essaye de prédire la langue d'origine d'un prénom/nom de famille. \n",
        "\n",
        "Ce TP montre comment faire le prétraitement de textes \"à partir de zéro\",sans utiliser les fonctions pratiques de torchtext.\n",
        "\n",
        "Nous allons définir notre propre RNN en créant une classe RNN qui hérite de l'objet nn.Module de PyTorch. Nous prenons la prédiction finale du RNN comme étant la sortie finale, c'est-à-dire la classe à laquelle appartient le mot.\n",
        "\n",
        "Nous allons entraîner le modèle sur quelques milliers de prénoms/noms de 18 langues d'origine, et prédire de quelle langue est un nouveau prénom/nom en fonction de l'orthographe.\n",
        "\n",
        "Exemple :\n",
        "\n",
        "nom = 'Dominique'<br/>\n",
        "pred: 5 French<br/>\n",
        "GT: 5 French<br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBKqfNXM2uEc",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-29T13:30:34.663968Z",
          "start_time": "2019-11-29T13:30:34.130417Z"
        },
        "id": "m4Afgot_2uEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-29T13:30:35.342766Z",
          "start_time": "2019-11-29T13:30:34.833487Z"
        },
        "id": "cUJ5veUS2uEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.autograd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn0PuJNG_hO8",
        "colab_type": "text"
      },
      "source": [
        "# Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiPYdcth_gGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0a06cf03-577b-4784-dc14-8e6a1eadd2bd"
      },
      "source": [
        "!wget -O dataset.zip https://www.irit.fr/~Thomas.Pellegrini/ens/RNN/data_noms.zip\n",
        "!ls -alth dataset.zip\n",
        "!unzip -qq dataset.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-09 17:10:55--  https://www.irit.fr/~Thomas.Pellegrini/ens/RNN/data_noms.zip\n",
            "Resolving www.irit.fr (www.irit.fr)... 141.115.28.2\n",
            "Connecting to www.irit.fr (www.irit.fr)|141.115.28.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>]   2.75M  1.68MB/s    in 1.6s    \n",
            "\n",
            "2019-12-09 17:10:57 (1.68 MB/s) - ‘dataset.zip’ saved [2882130/2882130]\n",
            "\n",
            "-rw-r--r-- 1 root root 2.8M Dec  9 14:06 dataset.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgklDnl82uEq",
        "colab_type": "text"
      },
      "source": [
        "# Préparation des données\n",
        "\n",
        "Le répertoire data/names contient 18 fichiers texte nommés \"[Language].txt\". Chaque fichier contient une liste de noms, un nom par ligne, le plus souvent romanisés (nous avons besoin de les convertir d'Unicode en ASCII).\n",
        "\n",
        "Nous obtenons un dictionnaire de listes de noms par langue, {langue : [noms ...]}. Les variables génériques \"category\" et \"line\" (pour la langue et le nom dans notre cas) sont utilisées pour une extensibilité ultérieure possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-29T13:30:35.798942Z",
          "start_time": "2019-11-29T13:30:35.684743Z"
        },
        "id": "NZDBFvcH2uEr",
        "colab_type": "code",
        "outputId": "79bbb477-9841-4b45-8b21-b83cb54749e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def findFiles(path): return glob.glob(path)\n",
        "\n",
        "print(findFiles('data/names/*.txt'))\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Construction du dictionnaire category_lines, une liste de noms par langage\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "# Lire un fichier et split en lignes\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data/names/French.txt', 'data/names/Dutch.txt', 'data/names/Greek.txt', 'data/names/English.txt', 'data/names/Portuguese.txt', 'data/names/German.txt', 'data/names/Spanish.txt', 'data/names/Chinese.txt', 'data/names/Czech.txt', 'data/names/Vietnamese.txt', 'data/names/Korean.txt', 'data/names/Japanese.txt', 'data/names/Scottish.txt', 'data/names/Arabic.txt', 'data/names/Italian.txt', 'data/names/Polish.txt', 'data/names/Irish.txt', 'data/names/Russian.txt']\n",
            "Slusarski\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOw9RAjNDGMq",
        "colab_type": "text"
      },
      "source": [
        "Maintenant nous avons category_lines, un dictionnaire mappant chaque catégorie (langue) à une liste de lignes (noms). Nous avons aussi gardé une trace de all_categories (une liste de langues) et de n_categories pour référence ultérieure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-29T13:30:36.469427Z",
          "start_time": "2019-11-29T13:30:36.464464Z"
        },
        "id": "k1U4h2Hu2uEy",
        "colab_type": "code",
        "outputId": "8b92a43b-b9a0-4d35-8d4d-0afca21cfa88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(category_lines['Italian'][:5])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXkHJRYOFR2u",
        "colab_type": "text"
      },
      "source": [
        "Maintenant que nous avons tous les noms stockés, nous devons les transformer en tenseurs pour pouvoir les utiliser.\n",
        "\n",
        "Pour représenter une lettre unique, nous utilisons un vecteur one-hot de taille <1 x n_letters>. \n",
        "\n",
        "Pour faire un mot, nous créons une matrice 2D <line_length x 1 x n_letters>.\n",
        "\n",
        "Cette dimension supplémentaire est due au fait que PyTorch suppose que tout est en batchs - nous utilisons juste une taille de batch de 1 ici."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-29T13:30:37.092081Z",
          "start_time": "2019-11-29T13:30:37.077502Z"
        },
        "id": "L4S7VB0J2uE4",
        "colab_type": "code",
        "outputId": "02368355-b60f-4d67-b401-2ea8affd6004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Trouver l'indice d'une lettre dans all_letters, par exemple \"a\" = 0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "# Pour transformer un Tensor <1 x n_letters>\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Transformer une ligne en un tenseur <line_length x 1 x n_letters>,\n",
        "# ou un tableau de vecteurs one-hot\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "print('J:', letterToTensor('J'))\n",
        "\n",
        "print('Jones:', lineToTensor('Jones').size())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "J: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]])\n",
            "Jones: torch.Size([5, 1, 57])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTPc5zyE2uE8",
        "colab_type": "text"
      },
      "source": [
        "# Création du RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9FR5kMCGvUw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Nous allons créer un module RNN (principalement copié du tutoriel PyTorch for Torch users), composé de 2 couches linéaires qui fonctionnent sur un état d'entrée et un état caché, avec une couche LogSoftmax en sortie.\n",
        "\n",
        "Ce réseau est illustré dans la figure ci-dessous.\n",
        "\n",
        "![rnn](https://www.irit.fr/~Thomas.Pellegrini/ens/RNN/images/rnn_tp2.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-29T14:15:18.282192Z",
          "start_time": "2019-11-29T14:15:18.269451Z"
        },
        "id": "grQ8E5dX2uFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "257af102-217f-4b79-f7a6-1ee2bc13e164"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(??, ??)\n",
        "        self.i2o = nn.Linear(??, ??)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((??, ??), 1)\n",
        "        hidden = self.i2h(??)\n",
        "        output = self.i2o(??)\n",
        "        output = self.softmax(??)\n",
        "        return ??, ??\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-5dd283b0711c>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    self.i2h = nn.Linear(??, ??)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8VmOcrqLJqv",
        "colab_type": "text"
      },
      "source": [
        "Pour exécuter une étape de ce réseau, nous devons passer une entrée (dans notre cas, le tenseur de la lettre courante) et l'état caché précédent (que nous initialisons d'abord sous forme d'un vecteur de zéros). Nous récupérons la sortie (probabilité de chaque langue) et un état caché suivant (que nous conserverons pour la prochaine étape)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-29T14:15:18.711621Z",
          "start_time": "2019-11-29T14:15:18.703988Z"
        },
        "id": "rwAM6iTT2uFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = letterToTensor('A')\n",
        "hidden =torch.zeros(1, n_hidden)\n",
        "print(input.size(), hidden.size())\n",
        "output, next_hidden = rnn(input, hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lZYhdURLc93",
        "colab_type": "text"
      },
      "source": [
        "Pour des raisons d'efficacité, nous ne voulons pas créer un nouveau Tensor pour chaque étape, donc nous allons utiliser lineToTensor au lieu de letterToTensor et utiliser des slices. Ceci pourrait être encore optimisé par le pré-calcul des batchs de tenseurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T09:55:59.021189Z",
          "start_time": "2019-11-28T09:55:59.012339Z"
        },
        "id": "T6mxJEvj2uFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = lineToTensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9R4JEQzL2Zt",
        "colab_type": "text"
      },
      "source": [
        "Ici le résultat est un Tensor <1 x n_categories>, où chaque élément est la probabilité de cette catégorie.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spvRS1RZ2uFa",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GugtDDkTmPCJ",
        "colab_type": "text"
      },
      "source": [
        "Définissons quelques fonctions utiles tout d'abord. La première sert à interpréter les résultats du réseau, qui sont les probabilités pour chaque catégorie. Nous utilisons Tensor.topk pour obtenir l'index de la plus grande valeur :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-29T14:17:19.186572Z",
          "start_time": "2019-11-29T14:17:19.179962Z"
        },
        "id": "Pj7DPqnP2uFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(categoryFromOutput(output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o5w0yGnmoPX",
        "colab_type": "text"
      },
      "source": [
        "Nous voulons aussi un moyen rapide d'obtenir un exemple d'apprentissage (un nom et sa langue) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-29T14:17:14.706876Z",
          "start_time": "2019-11-29T14:17:14.691907Z"
        },
        "id": "Cq6zsQMT2uFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def randomTrainingExample():\n",
        "    category = randomChoice(all_categories)\n",
        "    line = randomChoice(category_lines[category])\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    line_tensor = lineToTensor(line)\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    print('categorie =', category, '/ ligne =', line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiouD3ZWpVwh",
        "colab_type": "text"
      },
      "source": [
        "Pour la fonction de perte nn.NLLLoss est appropriée, puisque la dernière couche du RNN est nn.LogSoftmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T09:56:39.745068Z",
          "start_time": "2019-11-28T09:56:39.741128Z"
        },
        "id": "3_Mu87WT2uFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T09:56:47.749602Z",
          "start_time": "2019-11-28T09:56:47.741196Z"
        },
        "id": "e0CVqamQ2uFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.005 # Si trop grand, risque d'explosion. Si trop petit, risque de ne pas avoir d'apprentissage\n",
        "\n",
        "def train(category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    # Update des params basique... SGD : ajout des gradients des parametres, multipliés par le learning rate \n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(-learning_rate, p.grad.data)\n",
        "\n",
        "    return output, loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T10:01:39.376813Z",
          "start_time": "2019-11-28T09:56:58.253239Z"
        },
        "id": "ECT1QRCa2uFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "\n",
        "# Liste des losses pour faire une figure\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Affichage de iter, loss, name et guess\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T13:21:51.361932Z",
          "start_time": "2019-11-28T13:21:51.140447Z"
        },
        "id": "Ee-BnUzr2uFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(all_losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lyaKvUQ2uF1",
        "colab_type": "text"
      },
      "source": [
        "# Évaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T13:22:01.182110Z",
          "start_time": "2019-11-28T13:21:54.273432Z"
        },
        "id": "WwW4aUOg2uF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Liste des prédictions correctes dans une matrice de confusion\n",
        "confusion = torch.zeros(n_categories, n_categories)\n",
        "n_confusion = 10000\n",
        "\n",
        "# Retourne la prédiction pour une ligne\n",
        "def evaluate(line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Passe sur un grand nb d'exemples et récupération du nombre de prédictions correctes\n",
        "for i in range(n_confusion):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output = evaluate(line_tensor)\n",
        "    guess, guess_i = categoryFromOutput(output)\n",
        "    category_i = all_categories.index(category)\n",
        "    confusion[category_i][guess_i] += 1\n",
        "\n",
        "# Normaliser en divisant chaque ligne par sa somme \n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()\n",
        "\n",
        "# Faire un plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion.numpy())\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# les axes\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
        "ax.set_yticklabels([''] + all_categories)\n",
        "\n",
        "# les ticks\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "# sphinx_gallery_thumbnail_number = 2\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T13:22:08.960837Z",
          "start_time": "2019-11-28T13:22:08.939280Z"
        },
        "id": "_hPeHVQ-2uGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(input_line, n_predictions=3):\n",
        "    print('\\n> %s' % input_line)\n",
        "    with torch.no_grad():\n",
        "        output = evaluate(lineToTensor(input_line))\n",
        "\n",
        "        # Obtenir les N top catégories\n",
        "        topv, topi = output.topk(n_predictions, 1, True)\n",
        "        predictions = []\n",
        "\n",
        "        for i in range(n_predictions):\n",
        "            value = topv[0][i].item()\n",
        "            category_index = topi[0][i].item()\n",
        "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "            predictions.append([value, all_categories[category_index]])\n",
        "\n",
        "predict('Dovesky')\n",
        "predict('Jackson')\n",
        "predict('Satoshi')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usEQFRnE2uGS",
        "colab_type": "text"
      },
      "source": [
        "# Pour aller plus loin : \"visualizing memorization\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T15:50:47.994047Z",
          "start_time": "2019-11-28T15:50:47.733519Z"
        },
        "id": "dULNdesK2uGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://distill.pub/2019/memorization-in-rnns/\n",
        "\n",
        "# nom = 'Dovesky'\n",
        "# nom = 'Jackson'\n",
        "# nom = 'Mohammed'\n",
        "# nom = 'Sébastien'\n",
        "nom = 'Dominique'\n",
        "# nom='Thomas'\n",
        "\n",
        "category_index = 5\n",
        "\n",
        "line_tensor = lineToTensor(nom)\n",
        "# print(line_tensor.size())\n",
        "# print(line_tensor[0,0])\n",
        "line_tensor.requires_grad_()\n",
        "\n",
        "gradient_groundtruth_list = []\n",
        "hidden = rnn.initHidden()\n",
        "for i in range(line_tensor.size()[0]):\n",
        "    output, hidden = rnn(line_tensor[i], hidden)\n",
        "    g_groundtruth = torch.autograd.grad(output[0, category_index], line_tensor, retain_graph=True)[0].data\n",
        "    gradient_groundtruth_list.append(g_groundtruth)\n",
        "#     print(i, g.size(), g)\n",
        "    \n",
        "topv, topi = output.topk(1, 1, True)\n",
        "category_index_predicted = topi[0][0].item()\n",
        "print('pred: %i %s' %(category_index_predicted, all_categories[category_index_predicted]))\n",
        "print('GT: %i %s' %(category_index, all_categories[category_index]))\n",
        "\n",
        "gradient_pred_list = []\n",
        "hidden = rnn.initHidden()\n",
        "for i in range(line_tensor.size()[0]):\n",
        "    output, hidden = rnn(line_tensor[i], hidden)\n",
        "    g = torch.autograd.grad(output[0, category_index_predicted], line_tensor, retain_graph=True)[0].data\n",
        "    gradient_pred_list.append(g)\n",
        "\n",
        "\n",
        "# On calcule la \"connectivity\"\n",
        "# https://discuss.pytorch.org/t/newbie-getting-the-gradient-with-respect-to-the-input/12709/2\n",
        "# g = torch.autograd.grad(output[0,category_index], line_tensor, retain_graph=True)[0].data\n",
        "# print(g.size())\n",
        "# g = torch.autograd.grad(outputs[:,0,category_index], line_tensor, retain_graph=True)[0].data\n",
        "\n",
        "connectivity = np.zeros((line_tensor.size()[0],line_tensor.size()[0]))\n",
        "\n",
        "for i in range(line_tensor.size()[0]):\n",
        "    char_index = letterToIndex(nom[i])\n",
        "#     print(i, g[i,0,char_index])\n",
        "    connectivity[:,i] = np.abs(gradient_groundtruth_list[i][:, 0, char_index].detach().cpu().numpy())\n",
        "#     print(nom[i], connectivity[:,i])\n",
        "    \n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(connectivity)\n",
        "plt.ylabel(\"Time step\", fontsize=14)\n",
        "toto = plt.yticks(ticks=range(len(nom)), fontsize=14)\n",
        "toto = plt.xticks(ticks=range(len(nom)), labels=list(nom), fontsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T15:50:49.093152Z",
          "start_time": "2019-11-28T15:50:48.801685Z"
        },
        "id": "Z--ETeOr2uGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "connectivity = np.zeros((line_tensor.size()[0],line_tensor.size()[0]))\n",
        "\n",
        "for i in range(line_tensor.size()[0]):\n",
        "    char_index = letterToIndex(nom[i])\n",
        "#     print(i, g[i,0,char_index])\n",
        "    connectivity[:,i] = np.abs(gradient_pred_list[i][:, 0, char_index].detach().cpu().numpy())\n",
        "#     print(nom[i], connectivity[:,i])\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(connectivity)\n",
        "plt.ylabel(\"Time step\", fontsize=14)\n",
        "toto = plt.yticks(ticks=range(len(nom)), fontsize=14)\n",
        "toto = plt.xticks(ticks=range(len(nom)), labels=list(nom), fontsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-28T15:17:30.680296Z",
          "start_time": "2019-11-28T15:17:30.668870Z"
        },
        "id": "phqYjk3n2uGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.autograd.grad?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXkaJzmF2uGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}